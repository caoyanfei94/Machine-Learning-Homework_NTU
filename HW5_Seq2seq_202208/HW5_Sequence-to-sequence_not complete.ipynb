{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d197752",
   "metadata": {},
   "source": [
    "## Homework 5: Sequence-to-sequence\n",
    "\n",
    "Author: Cao Yanfei\n",
    "\n",
    "### Sequence-to-Sequence Introduction\n",
    "- Typical sequence-to-sequence (seq2seq) models are **encoder-decoder models**, which usually consists of two parts, the encoder and decoder, respectively. These two parts can be implemented with **recurrent neural network (RNN)** or **transformer**, primarily to deal with input/output sequences of dynamic length.\n",
    "- **Encoder** encodes a sequence of inputs, such as text, video or audio, into a single vector, which can be viewed as the abstractive representation of the inputs, containing information of the whole sequence.\n",
    "- **Decoder** decodes the vector output of encoder one step at a time, until the final output sequence is complete. Every decoding step is affected by previous step(s). Generally, one would add **\"< BOS >\"** at the begining of the sequence to indicate start of decoding, and **\"< EOS >\"** at the end to indicate end of decoding.\n",
    "\n",
    "![seq2seq](https://i.imgur.com/0zeDyuI.png)\n",
    "\n",
    "### Homework Description\n",
    "- English to Chinese (Traditional) Translation\n",
    "    - Input: An English sentence (e.g. Tom is a student.)\n",
    "    - Output: The Chinese translation (e.g. 汤姆是个学生。)\n",
    "- TODO\n",
    "    - Train a simple **RNN seq2seq** to achieve translation.\n",
    "    - Switch to **transformer** model to boost performance.\n",
    "    - Apply **Back-translation** to further boost performance.\n",
    "\n",
    "### Download and Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcea4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'torch>=1.6.0' editdistance matplotlib sacrebleu sacremoses sentencepiece tqdm wandb\n",
    "# !pip install --upgrade jupyter ipywidgets\n",
    "\n",
    "# !git clone https://github.com/pytorch/fairseq.git\n",
    "# !cd fairseq && git checkout 9a1c497\n",
    "# !pip install --upgrade ./fairseq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23eb4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pdb, pprint, logging, os, random     # pprint: Data pretty printer\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import tqdm.auto as tqdm\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "from fairseq import utils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f591d6",
   "metadata": {},
   "source": [
    "### Fix Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4caa41e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 73\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc75f9d3",
   "metadata": {},
   "source": [
    "### Dataset Information\n",
    "\n",
    "### En-Zn Bilingual Parallel Corpus\n",
    "\n",
    "- [TED2020](#reimers-2020-multilingual-sentence-bert)\n",
    "    - Raw: 398,066 (sentences)\n",
    "    - Processed: 393,980 (sentences)\n",
    "\n",
    "### Testing Data\n",
    "\n",
    "- Size: 4,000 (sentences)\n",
    "- Chinese translation is undisclosed. The provided (.zh) file is pseudo tranlation, each line is a '。'\n",
    "\n",
    "### Dataset Download\n",
    "\n",
    "### Install [Megatools](https://megous.com/git/megatools/about/) (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30fcaff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!apt-get install megatools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076a561",
   "metadata": {},
   "source": [
    "### Download and Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3f057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset/rawdata'\n",
    "dataset_name = 'ted2020'\n",
    "urls = (\n",
    "    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214989&authkey=AGgQ-DaR8eFSl1A\"', \n",
    "    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214987&authkey=AA4qP_azsicwZZM\"',\n",
    "# # If the above links die, use the following instead. \n",
    "#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/ted2020.tgz\",\n",
    "#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/test.tgz\",\n",
    "# # If the above links die, use the following instead. \n",
    "#     \"https://mega.nz/#!vEcTCISJ!3Rw0eHTZWPpdHBTbQEqBDikDEdFPr7fI8WxaXK9yZ9U\",\n",
    "#     \"https://mega.nz/#!zNcnGIoJ!oPJX9AvVVs11jc0SaK6vxP_lFUNTkEcK2WbxJpvjU5Y\", \n",
    ")\n",
    "file_names = (\n",
    "    'ted2020.tgz',    # train & dev\n",
    "    'test.tgz',       # test\n",
    ")\n",
    "prefix = Path(data_dir).absolute() / dataset_name\n",
    "\n",
    "# prefix.mkdir(parents=True, exist_ok=True)\n",
    "# for u, f in zip(urls, file_names):\n",
    "#     path = prefix / f\n",
    "#     if not path.exists():\n",
    "#         if 'mega' in u:\n",
    "#             !megadl {u} --path {path}\n",
    "#         else:\n",
    "#             !wget {u} -O {path}\n",
    "#     if path.suffix == '.tgz':\n",
    "#         !tar -xvf {path} -C {prefix}\n",
    "#     elif path.suffix == \".zip\":\n",
    "#         !unzip -o {path} -d {prefix}\n",
    "\n",
    "# !mv {prefix/'raw.en'} {prefix/'train_dev.raw.en'}\n",
    "# !mv {prefix/'raw.zh'} {prefix/'train_dev.raw.zh'}\n",
    "# !mv {prefix/'test.en'} {prefix/'test.raw.en'}\n",
    "# !mv {prefix/'test.zh'} {prefix/'test.raw.zh'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1963ab",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe939ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = 'en'\n",
    "tgt_lang = 'zh'\n",
    "\n",
    "data_prefix = f'{prefix}\\\\train_dev.raw'\n",
    "test_prefix = f'{prefix}\\\\test.raw'\n",
    "\n",
    "# Show contents of the first five lines in designated file. \n",
    "# !head {data_prefix+'.'+src_lang} -n 5\n",
    "# !head {data_prefix+'.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee1115",
   "metadata": {},
   "source": [
    "### Preprocess Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d0c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def str_fw2hw(ustring):\n",
    "    '''\n",
    "    Full-width -> Half-width\n",
    "    '''\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = ''\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)                                 # ord() returns the Unicode code point for a one-character string\n",
    "            if inside_code == 12288:                                 # Full-width space: direct conversion -> Half-width space\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):    # Full-width chars (except space) conversion\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)                              # chr() returns a Unicode string of one character with ordinal i; 0 <= i <= 0x10ffff.\n",
    "        ss.append(rstring)\n",
    "    return ''.join(ss)                                               # str.join() concatenate strings in a iterable object to form a new string.\n",
    "\n",
    "def clean_s(s, lang):\n",
    "    if lang == 'en':\n",
    "        s = re.sub(r'\\([^()]*\\)', '', s)                             # remove ([text])\n",
    "        s = s.replace('-', '')                                       # str.replace() returns a copy with all occurrences of substring old replaced by new.\n",
    "        s = re.sub('([.,;!?()\\\"])', r' \\1', s)                       # keep punctuation\n",
    "    elif lang == 'zh': \n",
    "        s = str_fw2hw(s)\n",
    "        s = re.sub(r'\\([^()]*\\)', '', s)\n",
    "        s = s.replace(' ', '')\n",
    "        s = s.replace('—', '')\n",
    "        s = s.replace('“', '')\n",
    "        s = s.replace('”', '')\n",
    "        s = s.replace('_', '')\n",
    "        s = re.sub('([。,;!?()\\\"~「」])', r' \\1', s)\n",
    "    s = ' '.join(s.strip().split())                                  # str.strip() returns a copy of the string with leading and trailing whitespace removed.\n",
    "                                                                     # str.split() returns a list of the words in the string, using sep as the delimiter string.\n",
    "    return s\n",
    "\n",
    "def len_s(s, lang):\n",
    "    if lang == 'zh':\n",
    "        return len(s)\n",
    "    return len(s.split())\n",
    "\n",
    "def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n",
    "    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists(): \n",
    "        print(f'{prefix}.clean.{l1} & {prefix}.clean.{l2} exists. Skip cleaning.')\n",
    "        return\n",
    "    \n",
    "    with open(f'{prefix}.{l1}', 'r', encoding='UTF-8') as l1_in_f:\n",
    "        with open(f'{prefix}.{l2}', 'r', encoding='UTF-8') as l2_in_f:\n",
    "            with open(f'{prefix}.clean.{l1}', 'w', encoding='UTF-8') as l1_out_f:\n",
    "                with open(f'{prefix}.clean.{l2}', 'w', encoding='UTF-8') as l2_out_f:\n",
    "                    for s1 in l1_in_f:\n",
    "                        s1 = s1.strip()\n",
    "                        s2 = l2_in_f.readline().strip()\n",
    "                        s1 = clean_s(s1, l1)\n",
    "                        s2 = clean_s(s2, l2)\n",
    "                        s1_len = len_s(s1, l1)\n",
    "                        s2_len = len_s(s2, l2)\n",
    "                        if min_len > 0:    # Remove short sentence\n",
    "                            if s1_len < min_len or s2_len < min_len:\n",
    "                                continue\n",
    "                        if max_len > 0:    # Remove long sentence\n",
    "                            if s1_len > max_len or s2_len > max_len:\n",
    "                                continue\n",
    "                        if ratio > 0:      # Remove by ratio of length\n",
    "                            if s1_len / s2_len > ratio or s2_len / s1_len > ratio:\n",
    "                                continue\n",
    "                        print(s1, file=l1_out_f)\n",
    "                        print(s2, file=l2_out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea7e947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\train_dev.raw.clean.en & D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\train_dev.raw.clean.zh exists. Skip cleaning.\n",
      "D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\test.raw.clean.en & D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\test.raw.clean.zh exists. Skip cleaning.\n"
     ]
    }
   ],
   "source": [
    "clean_corpus(data_prefix, src_lang, tgt_lang)\n",
    "clean_corpus(test_prefix, src_lang, tgt_lang, ratio=-1, max_len=-1, min_len=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af61919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head {data_prefix+'.clean'+src_lang} -n 5\n",
    "# !head {data_prefix+'.clean'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea23e30",
   "metadata": {},
   "source": [
    "### Split into Training or Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38cc7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training or validation splits exist. Skip spliting.\n"
     ]
    }
   ],
   "source": [
    "valid_ratio = 0.01    # 3000~4000 would suffice\n",
    "train_ratio = 1- valid_ratio\n",
    "\n",
    "if (prefix / f'train.clean.{src_lang}').exists() \\\n",
    "and (prefix / f'train.clean.{tgt_lang}').exists() \\\n",
    "and (prefix / f'valid.clean.{src_lang}').exists() \\\n",
    "and (prefix / f'valid.clean.{tgt_lang}').exists():\n",
    "    print(f'training or validation splits exist. Skip spliting.')\n",
    "else:\n",
    "    line_num = sum(1 for line in open(f'{data_prefix}.clean.{src_lang}', encoding='UTF-8'))    # 'sum' comprehension\n",
    "    labels = list(range(line_num))\n",
    "    random.shuffle(labels)                 # random.shuffle(x): shuffle list x in place, and return None.\n",
    "    for lang in [src_lang, tgt_lang]:\n",
    "        train_f = open(os.path.join(data_dir, dataset_name, f'train.clean.{lang}'), 'w', encoding='UTF-8')\n",
    "        valid_f = open(os.path.join(data_dir, dataset_name, f'valid.clean.{lang}'), 'w', encoding='UTF-8')\n",
    "        count = 0\n",
    "        for line in open(f'{data_prefix}.clean.{lang}', 'r', encoding='UTF-8'):\n",
    "            if labels[count] / line_num < train_ratio:\n",
    "                train_f.write(line)\n",
    "            else: \n",
    "                valid_f.write(line)\n",
    "            count += 1\n",
    "        train_f.close()\n",
    "        valid_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c4825d",
   "metadata": {},
   "source": [
    "### Subword Units\n",
    "\n",
    "Out of vocabulary (OOV) has been a major problem in machine translation. This can be alleviated by using subword units.\n",
    "- We will use the [sentencepiece](#kudo-richardson-2018-sentencepiece) package\n",
    "- Select **'unigram' or 'byte-pair encoding (BPE)' algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e67458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020/spm8000.model exists. Skip spm_training.\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "vocab_size = 8000\n",
    "\n",
    "if (prefix / f'spm{vocab_size}.model').exists():\n",
    "    print(f'{prefix}/spm{vocab_size}.model exists. Skip spm_training.')\n",
    "else:\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=','.join([f'{prefix}/train.clean.{src_lang}',     # one-sentence-per-line raw corpus file\n",
    "                        f'{prefix}/valid.clean.{src_lang}',\n",
    "                        f'{prefix}/train.clean.{tgt_lang}', \n",
    "                        f'{prefix}/valid.clean.{tgt_lang}']), \n",
    "        model_prefix=prefix / f'spm{vocab_size}',               # output model name prefix. <model_name>.model and <model_name>.vocab are generated.\n",
    "        vocab_size=vocab_size, \n",
    "        character_coverage=1,                                   # amount of characters covered by the model\n",
    "        model_type='unigram',                                   # 'bpe' works as well\n",
    "        input_sentence_size=1e6, \n",
    "        shuffle_input_sentence=True, \n",
    "        normalization_rule_name='nmt_nfkc_cf', \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9252cc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\train.en exists. Skip spm_encode.\n",
      "D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\train.zh exists. Skip spm_encode.\n",
      "D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\valid.en exists. Skip spm_encode.\n",
      "D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\valid.zh exists. Skip spm_encode.\n",
      "D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\test.en exists. Skip spm_encode.\n",
      "D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\test.zh exists. Skip spm_encode.\n"
     ]
    }
   ],
   "source": [
    "spm_model = spm.SentencePieceProcessor(model_file=str(prefix / f'spm{vocab_size}.model'))\n",
    "in_tag = {\n",
    "    'train': 'train.clean', \n",
    "    'valid': 'valid.clean', \n",
    "    'test': 'test.raw.clean', \n",
    "}\n",
    "\n",
    "for split in ['train', 'valid', 'test']: \n",
    "    for lang in [src_lang, tgt_lang]: \n",
    "        out_path = prefix / f'{split}.{lang}'\n",
    "        if out_path.exists(): \n",
    "            print(f'{out_path} exists. Skip spm_encode.')\n",
    "        else: \n",
    "            with open(prefix / f'{split}.{lang}', 'w', encoding='UTF-8') as out_f: \n",
    "                with open(prefix / f'{in_tag[split]}.{lang}', 'r', encoding='UTF-8') as in_f: \n",
    "                    for line in in_f: \n",
    "                        line = line.strip()\n",
    "                        tok = spm_model.encode(line, out_type=str)\n",
    "                        print(' '.join(tok), file=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6ed21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head {data_dir+'/'+dataset_name+'/train.'+src_lang} -n 5\n",
    "# !head {data_dir+'/'+dataset_name+'/train.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d0252",
   "metadata": {},
   "source": [
    "### Binarize the Data with Fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3deeac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binpath = Path('./dataset/data-bin', dataset_name)\n",
    "# if binpath.exists(): \n",
    "#     print(binpath, 'exists, will not be overwritten!')\n",
    "# else:\n",
    "#     !python -m fairseq_cli.preprocess \\\n",
    "#         --source-lang {src_lang} \\\n",
    "#         --target-lang {tgt_lang} \\\n",
    "#         --trainpref {prefix / 'train'} \\\n",
    "#         --validpref {prefix / 'valid'} \\\n",
    "#         --testpref {prefix / 'test'} \\\n",
    "#         --destdir {binpath} \\\n",
    "#         --joined-dictionary \\\n",
    "#         --workers 2\n",
    "# \n",
    "# 2022-06-24 21:48:10 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='en', target_lang='zh', trainpref='D:\\\\codes\\\\pytorch_learning\\\\jupyter\\\\8-HW5_Seq2seq\\\\dataset\\\\rawdata\\\\ted2020\\\\train', validpref='D:\\\\codes\\\\pytorch_learning\\\\jupyter\\\\8-HW5_Seq2seq\\\\dataset\\\\rawdata\\\\ted2020\\\\valid', testpref='D:\\\\codes\\\\pytorch_learning\\\\jupyter\\\\8-HW5_Seq2seq\\\\dataset\\\\rawdata\\\\ted2020\\\\test', align_suffix=None, destdir='dataset\\\\data-bin\\\\ted2020', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=2)\n",
    "# 2022-06-24 21:49:11 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n",
    "# 2022-06-24 21:50:09 | INFO | fairseq_cli.preprocess | [en] D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\train.en: 390060 sents, 12207217 tokens, 0.0% replaced by <unk>\n",
    "# 2022-06-24 21:50:09 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n",
    "# 2022-06-24 21:50:13 | INFO | fairseq_cli.preprocess | [en] D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\valid.en: 3940 sents, 122292 tokens, 0.0% replaced by <unk>\n",
    "# 2022-06-24 21:50:13 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n",
    "# 2022-06-24 21:50:17 | INFO | fairseq_cli.preprocess | [en] D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\test.en: 4000 sents, 122808 tokens, 0.0% replaced by <unk>\n",
    "# 2022-06-24 21:50:17 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n",
    "# 2022-06-24 21:51:03 | INFO | fairseq_cli.preprocess | [zh] D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\train.zh: 390060 sents, 9321522 tokens, 0.0% replaced by <unk>\n",
    "# 2022-06-24 21:51:03 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n",
    "# 2022-06-24 21:51:07 | INFO | fairseq_cli.preprocess | [zh] D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\valid.zh: 3940 sents, 93085 tokens, 0.00537% replaced by <unk>\n",
    "# 2022-06-24 21:51:07 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n",
    "# 2022-06-24 21:51:11 | INFO | fairseq_cli.preprocess | [zh] D:\\codes\\pytorch_learning\\jupyter\\8-HW5_Seq2seq\\dataset\\rawdata\\ted2020\\test.zh: 4000 sents, 8000 tokens, 0.0% replaced by <unk>\n",
    "# 2022-06-24 21:51:11 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to dataset\\data-bin\\ted2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64822cca",
   "metadata": {},
   "source": [
    "### Configuration for Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "966a89c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Namespace(                               # argparse.Namespace\n",
    "    datadir='./dataset/data-bin/ted2020', \n",
    "    savedir='./checkpoints/rnn', \n",
    "    source_lang='en', \n",
    "    target_lang='zh',\n",
    "    \n",
    "    # CPU threads when fetching & processing data.\n",
    "    num_works=2, \n",
    "    \n",
    "    # Batch size in terms of tokens. Gradient accumulation increases the effective batchsize.\n",
    "    max_tokens=8192, \n",
    "    accum_steps=2, \n",
    "    \n",
    "    # The lr calculated from Noam lr scheduler. You can tune the maximum lr by this factor.\n",
    "    lr_factor=2, \n",
    "    lr_warmth=4000, \n",
    "    \n",
    "    # Clip gradient norm helps alleviate gradient exploding\n",
    "    clip_norm=1.0,\n",
    "    \n",
    "    # Maximum epochs for training\n",
    "    max_epoch=30, \n",
    "    start_epoch=1,\n",
    "    \n",
    "    # Beam size for beam search\n",
    "    beam=5, \n",
    "    \n",
    "    # Generate sequences of maximum length ax + b, where x is the source length\n",
    "    max_len_a=1.2, \n",
    "    max_len_b=10, \n",
    "    # When decoding, post process sentence by removing sentencepiece symbols and jieba tokenization.\n",
    "    post_process='sentencepiece', \n",
    "    \n",
    "    # Checkpoints\n",
    "    keep_last_epochs=5, \n",
    "    resume=None,        # if resume from checkpoint name (under config.savedir)\n",
    "    \n",
    "    # logging\n",
    "    use_wandb=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e3fac0",
   "metadata": {},
   "source": [
    "### Logging\n",
    "\n",
    "- logging package logs ordinary messages.\n",
    "- Wandb logs the loss, bleu, etc. in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99df600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s | %(levelname)s | %(name)s | %(message)s', \n",
    "    datefmt='%Y-%m-%d %H:%M:%S', \n",
    "    level='INFO',     # 'DEBUG' 'WARNING' 'ERROR'\n",
    "    stream=sys.stdout\n",
    ")\n",
    "\n",
    "proj = 'hw5.seq2seq'\n",
    "logger = logging.getLogger(proj)\n",
    "if config.use_wandb:\n",
    "    import wandb    # wandb is Weight & Bias, a stronger visualization platform than Tensorboard\n",
    "    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d39296",
   "metadata": {},
   "source": [
    "### CUDA Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "394eac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda_env = utils.CudaEnvironment()\n",
    "# utils.CudaEnvironment.pretty_print_cuda_env_list([cuda_env])\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193f30e",
   "metadata": {},
   "source": [
    "### Dataloading\n",
    "\n",
    "### We Borrow the Translation Task from fairseq\n",
    "\n",
    "- Used to load the binarized data created above\n",
    "- Well-implemented data iterator (dataloader)\n",
    "- Built-in task.source_dictionary and task.target_dictionary are also handy\n",
    "- Well-implemented beach search decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbf18c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:51:21 | INFO | fairseq.tasks.translation | [en] dictionary: 8000 types\n",
      "2022-06-27 13:51:21 | INFO | fairseq.tasks.translation | [zh] dictionary: 8000 types\n"
     ]
    }
   ],
   "source": [
    "from fairseq.tasks.translation import TranslationConfig, TranslationTask\n",
    "\n",
    "## Setup task\n",
    "task_cfg = TranslationConfig(\n",
    "    data=config.datadir, \n",
    "    source_lang=config.source_lang, \n",
    "    target_lang=config.target_lang, \n",
    "    train_subset='train', \n",
    "    required_seq_len_multiple=8, \n",
    "    dataset_impl='mmap', \n",
    "    # unsample_primary=1, \n",
    ")\n",
    "task = TranslationTask.setup_task(task_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85166f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:51:21 | INFO | hw5.seq2seq | Loading data for epoch 1.\n",
      "2022-06-27 13:51:21 | INFO | fairseq.data.data_utils | loaded 390,060 examples from: ./dataset/data-bin/ted2020\\train.en-zh.en\n",
      "2022-06-27 13:51:21 | INFO | fairseq.data.data_utils | loaded 390,060 examples from: ./dataset/data-bin/ted2020\\train.en-zh.zh\n",
      "2022-06-27 13:51:21 | INFO | fairseq.tasks.translation | ./dataset/data-bin/ted2020 train en-zh 390060 examples\n",
      "2022-06-27 13:51:22 | INFO | fairseq.data.data_utils | loaded 3,940 examples from: ./dataset/data-bin/ted2020\\valid.en-zh.en\n",
      "2022-06-27 13:51:22 | INFO | fairseq.data.data_utils | loaded 3,940 examples from: ./dataset/data-bin/ted2020\\valid.en-zh.zh\n",
      "2022-06-27 13:51:22 | INFO | fairseq.tasks.translation | ./dataset/data-bin/ted2020 valid en-zh 3940 examples\n"
     ]
    }
   ],
   "source": [
    "logger.info('Loading data for epoch 1.')\n",
    "task.load_dataset(split='train', epoch=1, combine=True)    # Combine if you have back-translation data.\n",
    "task.load_dataset(split='valid', epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5d9a953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2,\n",
      " 'source': tensor([  20,   14,    5,   86,  373, 2019,   61,  205, 2638,    8,  268,   45,\n",
      "         205, 2638,  659,   23,  461,  158,  138,    4,  102,  742,   23,   13,\n",
      "         271,    5,    4,  102, 2662,   23,   13,  121,  696,  513,    7,    2]),\n",
      " 'target': tensor([   6,  566, 1057,  308, 3559, 2955, 3186, 1700,  633,  134,    4, 1315,\n",
      "        1379,  524, 3188,  898,    4,  298, 7201, 4498, 4646, 3451, 2362, 3559,\n",
      "        2955,   94,  660, 1013,  570,    9, 1323,   10,    2])}\n",
      "(\"Source: it's not something everyone can get behind the way they get behind \"\n",
      " 'helping haiti , or ending aids , or fighting a famine .')\n",
      "'Target: 人們不能像拖延援助海地 ,抗擊愛滋病 ,或賑濟饑荒那樣拖延對原住民的幫助 。'\n"
     ]
    }
   ],
   "source": [
    "sample = task.dataset('valid')[2]\n",
    "pprint.pprint(sample)\n",
    "pprint.pprint(\n",
    "    'Source: ' + \\\n",
    "    task.source_dictionary.string(\n",
    "        sample['source'], \n",
    "        config.post_process, \n",
    "    )\n",
    ")\n",
    "\n",
    "pprint.pprint(\n",
    "    'Target: ' + \\\n",
    "    task.target_dictionary.string(\n",
    "        sample['target'], \n",
    "        config.post_process,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965a973",
   "metadata": {},
   "source": [
    "### Dataset Iterator\n",
    "\n",
    "- Controls every **batch** to contain no more than N tokens, which **optimizes GPU memory efficiency**.\n",
    "- **Shuffles** the training set for every epoch\n",
    "- **Ignore** sentences exceeding maximum length\n",
    "- **Pad** all sentences in a batch to the same length, which enables parallel computing by GPU\n",
    "- Add **EOS** and shift one token\n",
    "    - **Teacher forcing**: to train the model to predict the next token based on prefix, we feed the right shifted target sequence as the decoder input.\n",
    "    - Generally, prepending **BOS** to the target would do the job (as shown below).\n",
    "![seq2seq](https://i.imgur.com/0zeDyuI.png)\n",
    "    - In fairseq however, this is done by moving the EOS token to the beginning. Empirically, this has the same effect. For instance: \n",
    "```\n",
    "# output target (target) and Decoder input (prev_output_tokens):\n",
    "    EOS = 2\n",
    "    target = 419, 711, 238, 888, 792, 60, 968, 8, 2\n",
    "    prev_output_token = 2, 419, 711, 238, 888, 792, 60, 968, 8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "772f12d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:51:22 | WARNING | fairseq.tasks.fairseq_task | 2,549 samples have invalid sizes and will be skipped, max_positions=(20, 20), first few sample ids=[180, 2690, 3506, 178, 3652, 3000, 2681, 2940, 113, 546]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': tensor([1703,  747]),\n",
       " 'nsentences': 2,\n",
       " 'ntokens': 20,\n",
       " 'net_input': {'src_tokens': tensor([[   1,    1,    1,    1,    1,    1,    1,   53,    8,  818,  453,  830,\n",
       "             16,   57,    7,    2],\n",
       "          [   1,    1,    1,    1,    1,    1,    1, 2436,   12,  479,  967,   17,\n",
       "            933,    5,    7,    2]]),\n",
       "  'src_lengths': tensor([9, 9]),\n",
       "  'prev_output_tokens': tensor([[   2,  229,  156, 1953,  103,  624,  565, 2582, 5759,   10,    1,    1,\n",
       "              1,    1,    1,    1],\n",
       "          [   2,    6, 1411,  108,   74, 1610,   10, 2412, 1160, 1730,    1,    1,\n",
       "              1,    1,    1,    1]])},\n",
       " 'target': tensor([[ 229,  156, 1953,  103,  624,  565, 2582, 5759,   10,    2,    1,    1,\n",
       "             1,    1,    1,    1],\n",
       "         [   6, 1411,  108,   74, 1610,   10, 2412, 1160, 1730,    2,    1,    1,\n",
       "             1,    1,    1,    1]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_iterator(task, split, epoch=1, max_tokens=4000, num_workers=1, cached=True, seed=seed):\n",
    "    batch_iterator = task.get_batch_iterator(\n",
    "        dataset = task.dataset(split), \n",
    "        max_tokens=max_tokens, \n",
    "        max_sentences=None, \n",
    "        max_positions=utils.resolve_max_positions(\n",
    "            task.max_positions(), \n",
    "            max_tokens, \n",
    "        ), \n",
    "        ignore_invalid_inputs=True, \n",
    "        seed=seed, \n",
    "        num_workers=num_workers, \n",
    "        epoch=epoch, \n",
    "        disable_iterator_cache=not cached, \n",
    "        # Set this to False to speed up. However, if set to False, changing max_tokens beyond first call of this method has no effect.\n",
    "    )\n",
    "    return batch_iterator\n",
    "\n",
    "demo_epoch_obj = load_data_iterator(task, 'valid', epoch=1, max_tokens=20, num_workers=1, cached=False, seed=seed)\n",
    "demo_iter = demo_epoch_obj.next_epoch_itr(shuffle=True)\n",
    "sample = next(demo_iter)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f485a",
   "metadata": {},
   "source": [
    "- each batch is a python dict, with string key and Tensor value. Contents are described below:\n",
    "```python\n",
    "batch = {\n",
    "    'id': id,    # id for each example\n",
    "    'nsentences': len(samples),    # batch size (sentences)\n",
    "    'ntokens': ntokens,          # batch size (tokens)\n",
    "    'net_input': {\n",
    "        'src_tokens': src_tokens,   # sequence in source language\n",
    "        'src_lengths': src_lengths,  # sequence length of each example before padding\n",
    "        'prev_output_tokens': prev_output_tokens,   # right shifted target, as mentioned above.\n",
    "    }, \n",
    "    'target': target,    # target sequence\n",
    "}, \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8cc61e",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "- We again inderit fariseq's encoder, decoder and model, so that in the testing phase we can directly leverage fairseq's beam search decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82601ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models import (\n",
    "    FairseqEncoder, \n",
    "    FairseqIncrementalDecoder, \n",
    "    FairseqEncoderDecoderModel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c0b76",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "- The Encoder is a RNN or Transformer Encoder. The following description is for **RNN**. For every input token, Enocoder will generate an output vector and a hidden states vector, and the hidden states vector is passed on to the next step. In other words, **the Encoder sequentially reads in the input sequence, and outputs a single vector at each timestep, then finally outputs the final hidden states, or content vector, at the last timestep**.\n",
    "\n",
    "- Parameters:\n",
    "    - args\n",
    "        - encoder_embed_dim: The dimension of embeddings, this compresses the one-hot vector into fixed dimensions, which achieves dimension reduction.\n",
    "        - encoder_ffn_embed_dim: The dimension of hidden satates and output vectors\n",
    "        - encoder_layers: The number of layers for Encoder RNN\n",
    "        - drpout: Determines the probability of a neuron's activation being set to 0, in order to prevent overfitting. Generally this is applied in training, and removed in testing.\n",
    "    - dictionary: The dictionary provided by fairseq. It's used to obtain the padding index, and in turn the encoder padding mask.\n",
    "    - embed_tokens: An instance of token embeddings (nn.Embedding).\n",
    "- Inputs:\n",
    "    - src_tokens: integer sequence representing English (e.g. 1, 28, 29, 205, 2).\n",
    "- Outputs:\n",
    "    - outputs: The output of RNN at each timestep, can be further processed by Attention.\n",
    "    - final hiddens: The hidden states of each timestep, will be passed to decoder for decoding.\n",
    "    - encoder_padding_mask: This tells the decoder which position to ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87866481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoder(FairseqEncoder):\n",
    "    def __init__(self, args, dictionary, embed_tokens): \n",
    "        super().__init__(dictionary)\n",
    "        self.embed_tokens = embed_tokens\n",
    "        \n",
    "        self.embed_dim = args.encoder_embed_dim\n",
    "        self.hidden_dim = args.encoder_ffn_embed_dim\n",
    "        self.num_layers = args.encoder_layers\n",
    "        \n",
    "        self.dropout_in_module = nn.Dropout(args.dropout)\n",
    "        self.rnn = nn.GRU(    # GRU: Gated Recurrent Neural Network\n",
    "            self.embed_dim, \n",
    "            self.hidden_dim, \n",
    "            self.num_layers, \n",
    "            dropout=args.dropout, \n",
    "            batch_first=False, \n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout_in_module= nn.Dropout(args.dropout)\n",
    "        \n",
    "        self.padding_idx = directionary.pad()\n",
    "    \n",
    "    def combine_bidir(self, outs, bsz: int): \n",
    "        out = outs.view(self.num_layers, 2, bsz, -1).transpose(1, 2).contiguous()\n",
    "        return out.view(self.num_layers, bsz, -1)\n",
    "    \n",
    "    def forward(self, src_tokens, **unused): \n",
    "        bsz, seqlen = src_tokens.size()\n",
    "        \n",
    "        # Get embeddings\n",
    "        x = self.embed_tokens(src_tokens)\n",
    "        x = self.dropout_in_module(x)\n",
    "        \n",
    "        # B x T x C -> T x B x C\n",
    "        x = x.transpose(0, 1)\n",
    "        \n",
    "        # pass thru bidirectional RNN\n",
    "        h0 = x.new_zeros(2 * self.num_layers, bsz, self.hidden_dim)\n",
    "        x, final_hiddens = self.rnn(x, h0)\n",
    "        outputs = self.dropout_out_module(x)\n",
    "        # outputs = [sequence len, batch size, hid dim * directions]\n",
    "        # hidden = [num_layers * directions, batch size, hid dim]\n",
    "        \n",
    "        # Since Encoder is birectional, we need to concatencate the hidden states of two directions\n",
    "        final_hiddens = self.combine_bidir(final_hiddens, bsz)\n",
    "        # hidden = [num_layers x batch x num_directions*hidden]\n",
    "        \n",
    "        encoder_padding_mask = src_tokens.eq(self.padding_idx).t()\n",
    "        return tuple(\n",
    "            (\n",
    "                outputs,                  # seq_len x batch x hidden\n",
    "                final_hiddens,            # num_layers x batch x num_directions*hidden\n",
    "                encoder_padding_mask,     # seq_len x batch\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def reorder_encoder_out(self, encoder_out, new_order): \n",
    "        # This is used by fairseq's beam search. How and why is not particularly important here.\n",
    "        return tuple(\n",
    "            (\n",
    "                encoder_out[0].index_select(1, new_order), \n",
    "                encoder_out[1].index_select(1, new_order), \n",
    "                encoder_out[2].index_select(1, new_order), \n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aac0eb",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "- When the input sequence is long, 'content vector' alone cannot accurately represent the whole sequence, attention mechanism can provide the Decoder more information.\n",
    "- According to the **Decoder embeddings** of the current timestep, match the **Encoder outputs** with decoder embeddings to determine correlation, and then sum the Encoder outputs weighted by the correlation as the input to **Decoderz** RNN.\n",
    "- Common attention implementations use neural network / dot product as the correlation between **query** (decoder embeddings) and **key** (Encoder outputs), followed by **softmax** to obtain a distribution, and finally **values** (Encoder outputs) is weighted sum-ed by said distribution.\n",
    "- Parameters:\n",
    "    - input_embed_dim: dimensionality of key, should be that of the vector in decoder to attend others.\n",
    "    - source_embed_dim: dimensionality of query, should be that of the vector to be attended to (encoder outputs).\n",
    "    - output_embed_dim: dimensionality of value, should be that of the vector after attention, expected by the next layer. \n",
    "- Inputs:\n",
    "    - inputs: Is the key, the vector to attend to others.\n",
    "    - encoder_outputs: Is the query/value, the vector to be attended to.\n",
    "    - encoder_padding_mask: This tells the decoder which position to ignore.\n",
    "- Outputs:\n",
    "    - output: The context vector after attention.\n",
    "    - attention score: The attention distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8027edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module): \n",
    "    def __init__(self, input_embed_dim, source_embed_dim, output_embed_dim, bias=False): \n",
    "        super().__init()\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_embed_dim, source_embed_dim, bias=bias)\n",
    "        self.output_proj = nn.Linear(\n",
    "            input_embed_dim + source_embed_dim, output_embed_dim, bias=bias\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs, encoder_outputs, encoder_padding_mask):\n",
    "        # inputs: T, B, dim\n",
    "        # encoder_outputs: S x B x dim\n",
    "        # padding mask: S x B\n",
    "        \n",
    "        # convert all to batch first\n",
    "        inputs = inputs.transpose(1, 0)    # B, T, dim\n",
    "        encoder_outputs = encoder_outputs.transpose(1, 0)    # B, S, dim\n",
    "        encoder_padding_mask = encoder_padding_mask.transpose(1, 0)    # B, S\n",
    "        \n",
    "        # Project to the dimensionality of encoder_outputs\n",
    "        x = self.input_proj(inputs)\n",
    "        \n",
    "        # Compute attention\n",
    "        # (B, T, dim) x (B, dim, S) = (B, T, S)\n",
    "        attn_scores = torch.bmm(x, encoder_outputs.transpose(1, 2))    # torch.bmm() returns matrix multiplication of 2 tensors.\n",
    "        \n",
    "        # Cancel the attention at positions corresponding to padding\n",
    "        if encoder_padding_mask is not None:\n",
    "            # Leveraging broadcast  B, S -> (B, 1, S)\n",
    "            encoder_padding_mask = encoder_padding_mask.unsqueeze(1)\n",
    "            attn_scores = (\n",
    "                attn_scores.float()\n",
    "                .masked_fill_(encoder_padding_mask, float('-inf'))    # a.data.masker_fill_(mask, padding_value)    # pad a where is in line with the position of mask where mask == 1 with padding_value\n",
    "                .type_as(attn_scores)\n",
    "            )    # FP16 support: cast to float and back\n",
    "        \n",
    "        # Softmax on the dimension corresponding to source sequence\n",
    "        attn_scores = F.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # shape (B, T, S) x (B, S, dim) = (B, T, dim) weighted sum\n",
    "        x = torch.bmm(attn_scores, encoder_outputs)\n",
    "        \n",
    "        # shape (B, T, dim)\n",
    "        x = torch.cat((x, inputs), dim=-1)\n",
    "        x = torch.tanh(self.output_proj(x))    # concat + linear + tanh\n",
    "        \n",
    "        # restore shape (B, T, dim) -> (T, B, dim)\n",
    "        return x.transpose(1, 0), attn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f7bc3",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f9d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbc7f62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.78250000000003"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.2 * 3.1415 * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fae6028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.05 * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555d122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808008f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d0010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f97ec71",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "1. Original source: https://github.com/ga642381/ML2021-Spring/blob/main/HW05/HW05.ipynb\n",
    "2. Link to refernce [training curves](https://wandb.ai/george0828zhang/hw5.seq2seq.new).\n",
    "3. Expected run time on Colab with Tesla T4\n",
    "\n",
    "|Baseline|Details|Total Time|\n",
    "|-|:-:|:-:|\n",
    "|Simple|2m 15s $\\times$ 30 epochs|1hr 8m|\n",
    "|Medium|4m $\\times$ 30 epochs | 2hr|\n",
    "|Strong|8m $\\times$ 30 epochs (backward)<br>+1hr (back-translation)<br> + 15m $\\times$ 30 epochs (forward) | 12hr 30m|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test] *",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
